# 模型管理

组织管理员可在管理端控制台中管理系统中可用的模型。

## 添加模型

1.  使用超级管理员账号登录管理端控制台。
    
2.  在左侧导航栏中，选择“模型配置”。
    
3.  在“模型配置”页面，找到“待配置的模型”列表。在列表中，找到目标模型，点击对应卡片上的“添加LLM”。
    
    ![](images/105.jpg)
    
4.  完成模型基础信息配置，并点击提交。
    
    ![](images/106.jpg)

    参数说明如下表所示：

    | **参数** | **是否必填** | **说明** |
    | :- | :- | :- |
    | 模型别名 | 是 | 模型在系统中的显示名称，用于区分和管理多个模型实例。<br/>别名仅作为系统内部标识和展示使用，不影响实际调用的模型。 |
    | 模型类型 | 是 | MAXIR AI 针对特定模型进行过 Prompt 调优。该参数用于标识 MAXIR AI 使用不同模型优化后的 Prompt。 |
    | 模型用途 | 是 | 定义模型在系统中的应用场景。可能值包括：<br/>- Chat：对话生成    <br/>- Embedding：文本嵌入    <br/>- Rerank：排序   <br/>- NL2SQL：SQL 代码生成    <br/>- NL2Python：Python 代码生成 |
    | 模型名称 | 是 | 模型在供应商侧的注册名称或部署名称，例如 OpenAI 的 `gpt-4o`。<br/>部分平台（如 Azure）需要填写“部署名”而不是通用模型类型。<br/>配置错误会导致接口调用失败。 |
    | API Key | 否 | 用于身份验证和访问模型服务的密钥。 |
    | 基础 URL | 是 | 模型服务的接口地址。例如 `https://api.openai.com/v1` 或供应商提供的专用地址。在自托管或代理场景下需要手动填写。 |
    | 最大 Token 数 | 是 | 单次请求中允许的最大 Token 数，包括输入提示词、上下文和输出内容。<br/>该参数受模型本身上下文窗口限制，合理配置有助于避免报错和控制资源消耗。 |
    | 启用思考模式 | 否 | 模型是否开启了推理/思考能力。 |
    | 额外参数 | 否 | 用于指定额外参数。 |

## 管理已配置模型

在“模型管理”页面中，组织管理员可查看所有已配置的模型实例信息，并执行查看、修改或删除操作。

### 查看已配置的模型实例

在“模型管理”页面，找到“已配置的模型”列表。该列表提供了模型实例的基本信息，包括模型的别名、模型的名称以及用途。

### 修改模型实例的信息

1.  在“模型管理”页面，找到“已配置的模型”列表。
    
2.  在“已配置的模型”列表中，找到目标模型实例，点击右侧的修改按钮。
    
    ![](images/107.jpg)
    
3.  修改对应信息，点击“提交”。
    
    ![](images/108.jpg)
    
    支持修改的配置项包括：
    
    - **模型别名**：模型在系统中的显示名称
        
    - **API Key**：用于身份验证和访问模型服务的密钥
        
    - **基础 URL**：模型服务的接口地址
        
    - **最大 Token 数**：单次请求中允许的最大 Token 数
        
    - **启用思考模式**：是否启用思考模式
        
    - **额外参数（可选）**：修改/添加额外参数
        

### 删除模型实例

1.  在“已配置的模型”列表中，找到目标模型实例，点击右侧的删除按钮。
    
    ![](images/109.jpg)
    
2.  在弹出的确认对话框中，点击“确认”。